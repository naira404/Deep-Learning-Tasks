{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dTx5wD5ezPDj"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ebd17ed3"
      },
      "source": [
        "# Task\n",
        "Develop a neural network model to predict stroke based on the \"stroke.csv\" dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5371ccae"
      },
      "source": [
        "## Load data\n",
        "\n",
        "### Subtask:\n",
        "Load the `stroke.csv` dataset into a pandas DataFrame.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "686fd310"
      },
      "source": [
        "**Reasoning**:\n",
        "Import pandas and load the data into a DataFrame.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "0a08b906",
        "outputId": "9c3c615b-12b7-40e5-804d-cb310febefb1"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('stroke.csv')\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   gender       age  hypertension  heart_disease  ever_married  work_type  \\\n",
              "0     0.5  0.816895           0.0            1.0           1.0       0.50   \n",
              "1     0.0  0.743652           0.0            0.0           1.0       0.75   \n",
              "2     0.5  0.975586           0.0            1.0           1.0       0.50   \n",
              "3     0.0  0.597168           0.0            0.0           1.0       0.50   \n",
              "4     0.0  0.963379           1.0            0.0           1.0       0.75   \n",
              "\n",
              "   Residence_type  avg_glucose_level       bmi  smoking_status  stroke  \n",
              "0             1.0           0.801265  0.301260        0.333333       1  \n",
              "1             0.0           0.679023  0.212981        0.666667       1  \n",
              "2             0.0           0.234512  0.254296        0.666667       1  \n",
              "3             1.0           0.536008  0.276060        1.000000       1  \n",
              "4             0.0           0.549349  0.156930        0.666667       1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0311cb9e-da9e-47e2-b6f0-4ac5c49f45f3\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>gender</th>\n",
              "      <th>age</th>\n",
              "      <th>hypertension</th>\n",
              "      <th>heart_disease</th>\n",
              "      <th>ever_married</th>\n",
              "      <th>work_type</th>\n",
              "      <th>Residence_type</th>\n",
              "      <th>avg_glucose_level</th>\n",
              "      <th>bmi</th>\n",
              "      <th>smoking_status</th>\n",
              "      <th>stroke</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.5</td>\n",
              "      <td>0.816895</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.50</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.801265</td>\n",
              "      <td>0.301260</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.743652</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.679023</td>\n",
              "      <td>0.212981</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.5</td>\n",
              "      <td>0.975586</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.234512</td>\n",
              "      <td>0.254296</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.597168</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.50</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.536008</td>\n",
              "      <td>0.276060</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.963379</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.549349</td>\n",
              "      <td>0.156930</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0311cb9e-da9e-47e2-b6f0-4ac5c49f45f3')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-0311cb9e-da9e-47e2-b6f0-4ac5c49f45f3 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-0311cb9e-da9e-47e2-b6f0-4ac5c49f45f3');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-cac9e562-5a88-443b-bc5d-aa6d840b8766\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-cac9e562-5a88-443b-bc5d-aa6d840b8766')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-cac9e562-5a88-443b-bc5d-aa6d840b8766 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 9722,\n  \"fields\": [\n    {\n      \"column\": \"gender\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.24244148138790042,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 574,\n        \"samples\": [\n          0.3384644657971244,\n          0.1290519645802342,\n          0.2280134443575162\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.268021816969379,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 4505,\n        \"samples\": [\n          0.848963918880013,\n          0.9034850819577256,\n          0.62285748456721\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"hypertension\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.3785649698196118,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 14,\n        \"samples\": [\n          0.3740160860820464,\n          0.194142294665938,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"heart_disease\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.3159932907267237,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 41,\n        \"samples\": [\n          0.8899262398189428,\n          0.7985936907866478,\n          0.9758898065913332\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ever_married\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.41903364914870805,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 92,\n        \"samples\": [\n          0.9083472102430096,\n          0.1241073677137774,\n          0.4834022365230042\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"work_type\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.2343943264093496,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 1798,\n        \"samples\": [\n          0.2608716128954573,\n          0.1869040544335012,\n          0.6819285848229665\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Residence_type\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.49897611150453286,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 31,\n        \"samples\": [\n          0.0531574483324841,\n          0.1194488839642857,\n          0.1255829963333216\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"avg_glucose_level\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.24717790260891126,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 8591,\n        \"samples\": [\n          0.2989566983658018,\n          0.051611116240421,\n          0.7540393315483335\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"bmi\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.07460021337282652,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 4861,\n        \"samples\": [\n          0.1331308751948851,\n          0.248207385954274,\n          0.197526325463402\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"smoking_status\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.33044580076721347,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 1831,\n        \"samples\": [\n          0.2109342035538356,\n          0.1967091353088473,\n          0.8116558250080167\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"stroke\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dfab116a",
        "outputId": "22dea23a-1b34-4c6d-ff0e-d038a5e6aa97"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = df.drop('stroke', axis=1)\n",
        "y = df['stroke']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(\"X_train shape:\", X_train.shape)\n",
        "print(\"X_test shape:\", X_test.shape)\n",
        "print(\"y_train shape:\", y_train.shape)\n",
        "print(\"y_test shape:\", y_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape: (7777, 10)\n",
            "X_test shape: (1945, 10)\n",
            "y_train shape: (7777,)\n",
            "y_test shape: (1945,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 429
        },
        "id": "af08c8e9",
        "outputId": "463f4476-751e-42c3-ea29-d4285708e34b"
      },
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Dropout\n",
        "# Define the model architecture\n",
        "model = Sequential([\n",
        "    Dense(128, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(16, activation='relu'),\n",
        "    Dense(8, activation='relu'),\n",
        "\n",
        "    Dense(1, activation='sigmoid')  # Output layer for binary classification\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Print the model summary\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_5\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_5\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense_27 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │         \u001b[38;5;34m1,408\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_28 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_6 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_29 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_30 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │           \u001b[38;5;34m528\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_31 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │           \u001b[38;5;34m136\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_32 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m9\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense_27 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,408</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_28 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_29 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_30 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_31 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">136</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_32 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m12,417\u001b[0m (48.50 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,417</span> (48.50 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m12,417\u001b[0m (48.50 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,417</span> (48.50 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4881a01a",
        "outputId": "87e18316-c134-4655-8c65-1af1b9eaa7c7"
      },
      "source": [
        "history = model.fit(X_train, y_train, epochs=150, batch_size=16, validation_split=0.2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            "\u001b[1m389/389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9342 - loss: 0.1514 - val_accuracy: 0.9319 - val_loss: 0.1910\n",
            "Epoch 2/150\n",
            "\u001b[1m389/389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9369 - loss: 0.1535 - val_accuracy: 0.9396 - val_loss: 0.1973\n",
            "Epoch 3/150\n",
            "\u001b[1m389/389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9337 - loss: 0.1583 - val_accuracy: 0.9357 - val_loss: 0.1890\n",
            "Epoch 4/150\n",
            "\u001b[1m389/389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9382 - loss: 0.1518 - val_accuracy: 0.9479 - val_loss: 0.1712\n",
            "Epoch 5/150\n",
            "\u001b[1m389/389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9433 - loss: 0.1389 - val_accuracy: 0.9428 - val_loss: 0.1818\n",
            "Epoch 6/150\n",
            "\u001b[1m389/389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9462 - loss: 0.1423 - val_accuracy: 0.9306 - val_loss: 0.2230\n",
            "Epoch 7/150\n",
            "\u001b[1m389/389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9463 - loss: 0.1367 - val_accuracy: 0.9332 - val_loss: 0.2182\n",
            "Epoch 8/150\n",
            "\u001b[1m389/389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9412 - loss: 0.1542 - val_accuracy: 0.9325 - val_loss: 0.1896\n",
            "Epoch 9/150\n",
            "\u001b[1m389/389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9341 - loss: 0.1593 - val_accuracy: 0.9351 - val_loss: 0.2122\n",
            "Epoch 10/150\n",
            "\u001b[1m389/389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9334 - loss: 0.1602 - val_accuracy: 0.9383 - val_loss: 0.1899\n",
            "Epoch 11/150\n",
            "\u001b[1m389/389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9402 - loss: 0.1545 - val_accuracy: 0.9344 - val_loss: 0.1971\n",
            "Epoch 12/150\n",
            "\u001b[1m389/389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9365 - loss: 0.1650 - val_accuracy: 0.9351 - val_loss: 0.1976\n",
            "Epoch 13/150\n",
            "\u001b[1m389/389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9391 - loss: 0.1474 - val_accuracy: 0.9422 - val_loss: 0.1761\n",
            "Epoch 14/150\n",
            "\u001b[1m389/389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9450 - loss: 0.1275 - val_accuracy: 0.9332 - val_loss: 0.2066\n",
            "Epoch 15/150\n",
            "\u001b[1m389/389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9376 - loss: 0.1492 - val_accuracy: 0.9351 - val_loss: 0.2182\n",
            "Epoch 16/150\n",
            "\u001b[1m389/389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9437 - loss: 0.1460 - val_accuracy: 0.9338 - val_loss: 0.2015\n",
            "Epoch 17/150\n",
            "\u001b[1m389/389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9455 - loss: 0.1350 - val_accuracy: 0.9383 - val_loss: 0.1866\n",
            "Epoch 18/150\n",
            "\u001b[1m389/389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9398 - loss: 0.1516 - val_accuracy: 0.9364 - val_loss: 0.1866\n",
            "Epoch 19/150\n",
            "\u001b[1m389/389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9405 - loss: 0.1613 - val_accuracy: 0.9383 - val_loss: 0.2067\n",
            "Epoch 20/150\n",
            "\u001b[1m389/389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9372 - loss: 0.1476 - val_accuracy: 0.9409 - val_loss: 0.1931\n",
            "Epoch 21/150\n",
            "\u001b[1m389/389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9400 - loss: 0.1549 - val_accuracy: 0.9370 - val_loss: 0.1781\n",
            "Epoch 22/150\n",
            "\u001b[1m389/389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9397 - loss: 0.1469 - val_accuracy: 0.9351 - val_loss: 0.1940\n",
            "Epoch 23/150\n",
            "\u001b[1m389/389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9397 - loss: 0.1389 - val_accuracy: 0.9370 - val_loss: 0.1887\n",
            "Epoch 24/150\n",
            "\u001b[1m389/389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9363 - loss: 0.1507 - val_accuracy: 0.9332 - val_loss: 0.2076\n",
            "Epoch 25/150\n",
            "\u001b[1m389/389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9457 - loss: 0.1406 - val_accuracy: 0.9428 - val_loss: 0.1833\n",
            "Epoch 26/150\n",
            "\u001b[1m389/389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9461 - loss: 0.1415 - val_accuracy: 0.9389 - val_loss: 0.1907\n",
            "Epoch 27/150\n",
            "\u001b[1m389/389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9420 - loss: 0.1425 - val_accuracy: 0.9357 - val_loss: 0.1965\n",
            "Epoch 28/150\n",
            "\u001b[1m389/389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9458 - loss: 0.1357 - val_accuracy: 0.9370 - val_loss: 0.1912\n",
            "Epoch 29/150\n",
            "\u001b[1m389/389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9438 - loss: 0.1421 - val_accuracy: 0.9441 - val_loss: 0.1793\n",
            "Epoch 30/150\n",
            "\u001b[1m389/389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9399 - loss: 0.1434 - val_accuracy: 0.9383 - val_loss: 0.1835\n",
            "Epoch 31/150\n",
            "\u001b[1m389/389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9390 - loss: 0.1516 - val_accuracy: 0.9383 - val_loss: 0.1827\n",
            "Epoch 32/150\n",
            "\u001b[1m389/389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9380 - loss: 0.1417 - val_accuracy: 0.9312 - val_loss: 0.2166\n",
            "Epoch 33/150\n",
            "\u001b[1m389/389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9445 - loss: 0.1392 - val_accuracy: 0.9325 - val_loss: 0.2010\n",
            "Epoch 34/150\n",
            "\u001b[1m389/389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9431 - loss: 0.1406 - val_accuracy: 0.9389 - val_loss: 0.1718\n",
            "Epoch 35/150\n",
            "\u001b[1m389/389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9448 - loss: 0.1448 - val_accuracy: 0.9344 - val_loss: 0.2081\n",
            "Epoch 36/150\n",
            "\u001b[1m389/389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9449 - loss: 0.1347 - val_accuracy: 0.9396 - val_loss: 0.1872\n",
            "Epoch 37/150\n",
            "\u001b[1m389/389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9485 - loss: 0.1357 - val_accuracy: 0.9351 - val_loss: 0.1950\n",
            "Epoch 38/150\n",
            "\u001b[1m389/389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9416 - loss: 0.1440 - val_accuracy: 0.9377 - val_loss: 0.1923\n",
            "Epoch 39/150\n",
            "\u001b[1m389/389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9370 - loss: 0.1478 - val_accuracy: 0.9364 - val_loss: 0.1992\n",
            "Epoch 40/150\n",
            "\u001b[1m389/389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9454 - loss: 0.1334 - val_accuracy: 0.9325 - val_loss: 0.2112\n",
            "Epoch 41/150\n",
            "\u001b[1m389/389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9486 - loss: 0.1279 - val_accuracy: 0.9216 - val_loss: 0.2104\n",
            "Epoch 42/150\n",
            "\u001b[1m389/389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9417 - loss: 0.1524 - val_accuracy: 0.9383 - val_loss: 0.1838\n",
            "Epoch 43/150\n",
            "\u001b[1m389/389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9440 - loss: 0.1409 - val_accuracy: 0.9454 - val_loss: 0.1748\n",
            "Epoch 44/150\n",
            "\u001b[1m389/389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9489 - loss: 0.1243 - val_accuracy: 0.9351 - val_loss: 0.2035\n",
            "Epoch 45/150\n",
            "\u001b[1m389/389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9418 - loss: 0.1419 - val_accuracy: 0.9396 - val_loss: 0.1817\n",
            "Epoch 46/150\n",
            "\u001b[1m389/389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9458 - loss: 0.1328 - val_accuracy: 0.9364 - val_loss: 0.2194\n",
            "Epoch 47/150\n",
            "\u001b[1m389/389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9451 - loss: 0.1401 - val_accuracy: 0.9409 - val_loss: 0.1946\n",
            "Epoch 48/150\n",
            "\u001b[1m389/389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9399 - loss: 0.1462 - val_accuracy: 0.9389 - val_loss: 0.1901\n",
            "Epoch 49/150\n",
            "\u001b[1m389/389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9488 - loss: 0.1366 - val_accuracy: 0.9274 - val_loss: 0.2468\n",
            "Epoch 50/150\n",
            "\u001b[1m389/389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9399 - loss: 0.1474 - val_accuracy: 0.9325 - val_loss: 0.1921\n",
            "Epoch 51/150\n",
            "\u001b[1m389/389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9494 - loss: 0.1274 - val_accuracy: 0.9402 - val_loss: 0.1885\n",
            "Epoch 52/150\n",
            "\u001b[1m389/389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9404 - loss: 0.1442 - val_accuracy: 0.9402 - val_loss: 0.1881\n",
            "Epoch 53/150\n",
            "\u001b[1m389/389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9482 - loss: 0.1299 - val_accuracy: 0.9351 - val_loss: 0.1996\n",
            "Epoch 54/150\n",
            "\u001b[1m389/389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9384 - loss: 0.1469 - val_accuracy: 0.9344 - val_loss: 0.2142\n",
            "Epoch 55/150\n",
            "\u001b[1m389/389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9393 - loss: 0.1467 - val_accuracy: 0.9357 - val_loss: 0.1958\n",
            "Epoch 56/150\n",
            "\u001b[1m389/389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9442 - loss: 0.1361 - val_accuracy: 0.9364 - val_loss: 0.1844\n",
            "Epoch 57/150\n",
            "\u001b[1m389/389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9437 - loss: 0.1334 - val_accuracy: 0.9280 - val_loss: 0.2076\n",
            "Epoch 58/150\n",
            "\u001b[1m389/389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9446 - loss: 0.1386 - val_accuracy: 0.9280 - val_loss: 0.2146\n",
            "Epoch 59/150\n",
            "\u001b[1m389/389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9377 - loss: 0.1526 - val_accuracy: 0.9338 - val_loss: 0.1907\n",
            "Epoch 60/150\n",
            "\u001b[1m389/389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9393 - loss: 0.1523 - val_accuracy: 0.9306 - val_loss: 0.2179\n",
            "Epoch 61/150\n",
            "\u001b[1m389/389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9482 - loss: 0.1352 - val_accuracy: 0.9364 - val_loss: 0.1995\n",
            "Epoch 62/150\n",
            "\u001b[1m389/389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9424 - loss: 0.1474 - val_accuracy: 0.9344 - val_loss: 0.1993\n",
            "Epoch 63/150\n",
            "\u001b[1m389/389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9463 - loss: 0.1332 - val_accuracy: 0.9441 - val_loss: 0.1897\n",
            "Epoch 64/150\n",
            "\u001b[1m389/389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9417 - loss: 0.1427 - val_accuracy: 0.9409 - val_loss: 0.1719\n",
            "Epoch 65/150\n",
            "\u001b[1m389/389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9469 - loss: 0.1293 - val_accuracy: 0.9357 - val_loss: 0.1859\n",
            "Epoch 66/150\n",
            "\u001b[1m389/389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9408 - loss: 0.1437 - val_accuracy: 0.9332 - val_loss: 0.1958\n",
            "Epoch 67/150\n",
            "\u001b[1m389/389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9501 - loss: 0.1309 - val_accuracy: 0.9434 - val_loss: 0.1755\n",
            "Epoch 68/150\n",
            "\u001b[1m389/389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9505 - loss: 0.1299 - val_accuracy: 0.9402 - val_loss: 0.1942\n",
            "Epoch 69/150\n",
            "\u001b[1m389/389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9481 - loss: 0.1350 - val_accuracy: 0.9325 - val_loss: 0.2049\n",
            "Epoch 70/150\n",
            "\u001b[1m389/389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9435 - loss: 0.1398 - val_accuracy: 0.9364 - val_loss: 0.1965\n",
            "Epoch 71/150\n",
            "\u001b[1m389/389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9498 - loss: 0.1315 - val_accuracy: 0.9370 - val_loss: 0.1932\n",
            "Epoch 72/150\n",
            "\u001b[1m389/389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9492 - loss: 0.1260 - val_accuracy: 0.9312 - val_loss: 0.1991\n",
            "Epoch 73/150\n",
            "\u001b[1m389/389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9481 - loss: 0.1229 - val_accuracy: 0.9396 - val_loss: 0.1935\n",
            "Epoch 74/150\n",
            "\u001b[1m389/389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9436 - loss: 0.1357 - val_accuracy: 0.9454 - val_loss: 0.1871\n",
            "Epoch 75/150\n",
            "\u001b[1m389/389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9526 - loss: 0.1284 - val_accuracy: 0.9396 - val_loss: 0.1894\n",
            "Epoch 76/150\n",
            "\u001b[1m389/389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9378 - loss: 0.1505 - val_accuracy: 0.9383 - val_loss: 0.2034\n",
            "Epoch 77/150\n",
            "\u001b[1m389/389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9492 - loss: 0.1294 - val_accuracy: 0.9389 - val_loss: 0.1967\n",
            "Epoch 78/150\n",
            "\u001b[1m389/389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9428 - loss: 0.1409 - val_accuracy: 0.9357 - val_loss: 0.2044\n",
            "Epoch 79/150\n",
            "\u001b[1m389/389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9450 - loss: 0.1405 - val_accuracy: 0.9338 - val_loss: 0.2033\n",
            "Epoch 80/150\n",
            "\u001b[1m389/389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9464 - loss: 0.1302 - val_accuracy: 0.9415 - val_loss: 0.1896\n",
            "Epoch 81/150\n",
            "\u001b[1m389/389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9492 - loss: 0.1303 - val_accuracy: 0.9409 - val_loss: 0.1841\n",
            "Epoch 82/150\n",
            "\u001b[1m389/389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9418 - loss: 0.1363 - val_accuracy: 0.9338 - val_loss: 0.1892\n",
            "Epoch 83/150\n",
            "\u001b[1m389/389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9481 - loss: 0.1287 - val_accuracy: 0.9325 - val_loss: 0.2058\n",
            "Epoch 84/150\n",
            "\u001b[1m389/389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9487 - loss: 0.1376 - val_accuracy: 0.9467 - val_loss: 0.1840\n",
            "Epoch 85/150\n",
            "\u001b[1m389/389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9371 - loss: 0.1471 - val_accuracy: 0.9344 - val_loss: 0.1978\n",
            "Epoch 86/150\n",
            "\u001b[1m389/389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9490 - loss: 0.1321 - val_accuracy: 0.9415 - val_loss: 0.2085\n",
            "Epoch 87/150\n",
            "\u001b[1m389/389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9481 - loss: 0.1298 - val_accuracy: 0.9325 - val_loss: 0.2093\n",
            "Epoch 88/150\n",
            "\u001b[1m389/389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9463 - loss: 0.1307 - val_accuracy: 0.9370 - val_loss: 0.1994\n",
            "Epoch 89/150\n",
            "\u001b[1m389/389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9524 - loss: 0.1172 - val_accuracy: 0.9460 - val_loss: 0.1718\n",
            "Epoch 90/150\n",
            "\u001b[1m389/389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9504 - loss: 0.1259 - val_accuracy: 0.9434 - val_loss: 0.2042\n",
            "Epoch 91/150\n",
            "\u001b[1m389/389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9481 - loss: 0.1316 - val_accuracy: 0.9402 - val_loss: 0.1940\n",
            "Epoch 92/150\n",
            "\u001b[1m389/389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9504 - loss: 0.1335 - val_accuracy: 0.9409 - val_loss: 0.1903\n",
            "Epoch 93/150\n",
            "\u001b[1m389/389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9467 - loss: 0.1301 - val_accuracy: 0.9454 - val_loss: 0.1901\n",
            "Epoch 94/150\n",
            "\u001b[1m389/389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9457 - loss: 0.1266 - val_accuracy: 0.9409 - val_loss: 0.1741\n",
            "Epoch 95/150\n",
            "\u001b[1m389/389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9481 - loss: 0.1258 - val_accuracy: 0.9364 - val_loss: 0.2077\n",
            "Epoch 96/150\n",
            "\u001b[1m389/389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9403 - loss: 0.1460 - val_accuracy: 0.9441 - val_loss: 0.2159\n",
            "Epoch 97/150\n",
            "\u001b[1m389/389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9388 - loss: 0.1464 - val_accuracy: 0.9377 - val_loss: 0.1954\n",
            "Epoch 98/150\n",
            "\u001b[1m389/389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9489 - loss: 0.1267 - val_accuracy: 0.9357 - val_loss: 0.1993\n",
            "Epoch 99/150\n",
            "\u001b[1m389/389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9432 - loss: 0.1391 - val_accuracy: 0.9409 - val_loss: 0.2278\n",
            "Epoch 100/150\n",
            "\u001b[1m389/389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9566 - loss: 0.1134 - val_accuracy: 0.9293 - val_loss: 0.2532\n",
            "Epoch 101/150\n",
            "\u001b[1m389/389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9418 - loss: 0.1474 - val_accuracy: 0.9332 - val_loss: 0.2077\n",
            "Epoch 102/150\n",
            "\u001b[1m389/389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9502 - loss: 0.1262 - val_accuracy: 0.9415 - val_loss: 0.1931\n",
            "Epoch 103/150\n",
            "\u001b[1m389/389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9462 - loss: 0.1394 - val_accuracy: 0.9454 - val_loss: 0.1852\n",
            "Epoch 104/150\n",
            "\u001b[1m389/389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9530 - loss: 0.1270 - val_accuracy: 0.9389 - val_loss: 0.1937\n",
            "Epoch 105/150\n",
            "\u001b[1m389/389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9490 - loss: 0.1258 - val_accuracy: 0.9351 - val_loss: 0.2070\n",
            "Epoch 106/150\n",
            "\u001b[1m389/389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9474 - loss: 0.1283 - val_accuracy: 0.9422 - val_loss: 0.2005\n",
            "Epoch 107/150\n",
            "\u001b[1m389/389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9466 - loss: 0.1363 - val_accuracy: 0.9396 - val_loss: 0.2051\n",
            "Epoch 108/150\n",
            "\u001b[1m389/389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9494 - loss: 0.1334 - val_accuracy: 0.9344 - val_loss: 0.1997\n",
            "Epoch 109/150\n",
            "\u001b[1m389/389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9443 - loss: 0.1330 - val_accuracy: 0.9338 - val_loss: 0.2051\n",
            "Epoch 110/150\n",
            "\u001b[1m389/389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9514 - loss: 0.1265 - val_accuracy: 0.9409 - val_loss: 0.2015\n",
            "Epoch 111/150\n",
            "\u001b[1m389/389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9481 - loss: 0.1271 - val_accuracy: 0.9441 - val_loss: 0.1802\n",
            "Epoch 112/150\n",
            "\u001b[1m389/389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9471 - loss: 0.1323 - val_accuracy: 0.9422 - val_loss: 0.1937\n",
            "Epoch 113/150\n",
            "\u001b[1m389/389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9464 - loss: 0.1316 - val_accuracy: 0.9222 - val_loss: 0.2300\n",
            "Epoch 114/150\n",
            "\u001b[1m389/389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9447 - loss: 0.1343 - val_accuracy: 0.9319 - val_loss: 0.2040\n",
            "Epoch 115/150\n",
            "\u001b[1m389/389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9529 - loss: 0.1199 - val_accuracy: 0.9422 - val_loss: 0.2046\n",
            "Epoch 116/150\n",
            "\u001b[1m389/389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9479 - loss: 0.1308 - val_accuracy: 0.9434 - val_loss: 0.2009\n",
            "Epoch 117/150\n",
            "\u001b[1m389/389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9537 - loss: 0.1161 - val_accuracy: 0.9447 - val_loss: 0.1680\n",
            "Epoch 118/150\n",
            "\u001b[1m389/389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9522 - loss: 0.1197 - val_accuracy: 0.9402 - val_loss: 0.1889\n",
            "Epoch 119/150\n",
            "\u001b[1m389/389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9501 - loss: 0.1346 - val_accuracy: 0.9434 - val_loss: 0.1996\n",
            "Epoch 120/150\n",
            "\u001b[1m389/389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9574 - loss: 0.1169 - val_accuracy: 0.9364 - val_loss: 0.1887\n",
            "Epoch 121/150\n",
            "\u001b[1m389/389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9525 - loss: 0.1235 - val_accuracy: 0.9389 - val_loss: 0.1857\n",
            "Epoch 122/150\n",
            "\u001b[1m389/389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9483 - loss: 0.1290 - val_accuracy: 0.9364 - val_loss: 0.1842\n",
            "Epoch 123/150\n",
            "\u001b[1m389/389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9570 - loss: 0.1142 - val_accuracy: 0.9396 - val_loss: 0.1938\n",
            "Epoch 124/150\n",
            "\u001b[1m389/389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9550 - loss: 0.1210 - val_accuracy: 0.9441 - val_loss: 0.1871\n",
            "Epoch 125/150\n",
            "\u001b[1m389/389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9533 - loss: 0.1200 - val_accuracy: 0.9441 - val_loss: 0.1897\n",
            "Epoch 126/150\n",
            "\u001b[1m389/389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9510 - loss: 0.1211 - val_accuracy: 0.9364 - val_loss: 0.2081\n",
            "Epoch 127/150\n",
            "\u001b[1m389/389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9463 - loss: 0.1250 - val_accuracy: 0.9486 - val_loss: 0.1857\n",
            "Epoch 128/150\n",
            "\u001b[1m389/389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9554 - loss: 0.1098 - val_accuracy: 0.9287 - val_loss: 0.2082\n",
            "Epoch 129/150\n",
            "\u001b[1m389/389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9528 - loss: 0.1264 - val_accuracy: 0.9370 - val_loss: 0.1914\n",
            "Epoch 130/150\n",
            "\u001b[1m389/389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9486 - loss: 0.1328 - val_accuracy: 0.9357 - val_loss: 0.1819\n",
            "Epoch 131/150\n",
            "\u001b[1m389/389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9478 - loss: 0.1325 - val_accuracy: 0.9422 - val_loss: 0.1922\n",
            "Epoch 132/150\n",
            "\u001b[1m389/389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9509 - loss: 0.1285 - val_accuracy: 0.9344 - val_loss: 0.1914\n",
            "Epoch 133/150\n",
            "\u001b[1m389/389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9569 - loss: 0.1190 - val_accuracy: 0.9454 - val_loss: 0.1932\n",
            "Epoch 134/150\n",
            "\u001b[1m389/389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9536 - loss: 0.1114 - val_accuracy: 0.9332 - val_loss: 0.1999\n",
            "Epoch 135/150\n",
            "\u001b[1m389/389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9490 - loss: 0.1251 - val_accuracy: 0.9434 - val_loss: 0.1872\n",
            "Epoch 136/150\n",
            "\u001b[1m389/389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9488 - loss: 0.1349 - val_accuracy: 0.9409 - val_loss: 0.1936\n",
            "Epoch 137/150\n",
            "\u001b[1m389/389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9491 - loss: 0.1273 - val_accuracy: 0.9467 - val_loss: 0.1977\n",
            "Epoch 138/150\n",
            "\u001b[1m389/389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9515 - loss: 0.1206 - val_accuracy: 0.9434 - val_loss: 0.1942\n",
            "Epoch 139/150\n",
            "\u001b[1m389/389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9494 - loss: 0.1271 - val_accuracy: 0.9441 - val_loss: 0.1710\n",
            "Epoch 140/150\n",
            "\u001b[1m389/389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9522 - loss: 0.1165 - val_accuracy: 0.9428 - val_loss: 0.2101\n",
            "Epoch 141/150\n",
            "\u001b[1m389/389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9458 - loss: 0.1349 - val_accuracy: 0.9460 - val_loss: 0.1991\n",
            "Epoch 142/150\n",
            "\u001b[1m389/389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9544 - loss: 0.1180 - val_accuracy: 0.9441 - val_loss: 0.2033\n",
            "Epoch 143/150\n",
            "\u001b[1m389/389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9523 - loss: 0.1203 - val_accuracy: 0.9454 - val_loss: 0.1788\n",
            "Epoch 144/150\n",
            "\u001b[1m389/389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9471 - loss: 0.1271 - val_accuracy: 0.9389 - val_loss: 0.2058\n",
            "Epoch 145/150\n",
            "\u001b[1m389/389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9607 - loss: 0.1084 - val_accuracy: 0.9409 - val_loss: 0.1946\n",
            "Epoch 146/150\n",
            "\u001b[1m389/389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9567 - loss: 0.1135 - val_accuracy: 0.9370 - val_loss: 0.2181\n",
            "Epoch 147/150\n",
            "\u001b[1m389/389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9533 - loss: 0.1183 - val_accuracy: 0.9499 - val_loss: 0.1620\n",
            "Epoch 148/150\n",
            "\u001b[1m389/389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9490 - loss: 0.1277 - val_accuracy: 0.9357 - val_loss: 0.2172\n",
            "Epoch 149/150\n",
            "\u001b[1m389/389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9491 - loss: 0.1295 - val_accuracy: 0.9441 - val_loss: 0.1996\n",
            "Epoch 150/150\n",
            "\u001b[1m389/389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9550 - loss: 0.1230 - val_accuracy: 0.9415 - val_loss: 0.2023\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"Test Loss: {loss:.4f}\")\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o5lnbkvuIGTW",
        "outputId": "7ed6b9d1-a43a-4cf7-c5d0-20edbfe40171"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9301 - loss: 0.2418\n",
            "Test Loss: 0.2379\n",
            "Test Accuracy: 0.9337\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_LUIizTYJcsJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}